{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"_I2iygzDCCgN"},"outputs":[],"source":["# Install Java, Spark, and Findspark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"gNK3MPgRCD3v"},"outputs":[],"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Yelp_NLP\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"colab_type":"code","executionInfo":{"elapsed":8090,"status":"ok","timestamp":1588299651244,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"},"user_tz":420},"id":"k1mozi3rCPzw","outputId":"d280b477-c011-4aae-ce53-fddf2510c970"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------+\n","|   class|                text|\n","+--------+--------------------+\n","|positive|Wow... Loved this...|\n","|negative|  Crust is not good.|\n","|negative|Not tasty and the...|\n","|positive|Stopped by during...|\n","|positive|The selection on ...|\n","|negative|Now I am getting ...|\n","|negative|Honeslty it didn'...|\n","|negative|The potatoes were...|\n","|positive|The fries were gr...|\n","|positive|      A great touch.|\n","|positive|Service was very ...|\n","|negative|  Would not go back.|\n","|negative|The cashier had n...|\n","|positive|I tried the Cape ...|\n","|negative|I was disgusted b...|\n","|negative|I was shocked bec...|\n","|positive| Highly recommended.|\n","|negative|Waitress was a li...|\n","|negative|This place is not...|\n","|negative|did not like at all.|\n","+--------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Read in data from S3 Buckets\n","from pyspark import SparkFiles\n","url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n","\n","# Show DataFrame\n","df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"m-U4ecqQCTi-"},"outputs":[],"source":["# Import functions that will be used in NLP process (pipeline)\n","from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"colab_type":"code","executionInfo":{"elapsed":858,"status":"ok","timestamp":1588299698134,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"},"user_tz":420},"id":"cGL9P_6bCWEV","outputId":"ce44fb07-8be5-4bc6-afff-b2ede203798f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------+------+\n","|   class|                text|length|\n","+--------+--------------------+------+\n","|positive|Wow... Loved this...|    24|\n","|negative|  Crust is not good.|    18|\n","|negative|Not tasty and the...|    41|\n","|positive|Stopped by during...|    87|\n","|positive|The selection on ...|    59|\n","|negative|Now I am getting ...|    46|\n","|negative|Honeslty it didn'...|    37|\n","|negative|The potatoes were...|   111|\n","|positive|The fries were gr...|    25|\n","|positive|      A great touch.|    14|\n","|positive|Service was very ...|    24|\n","|negative|  Would not go back.|    18|\n","|negative|The cashier had n...|    99|\n","|positive|I tried the Cape ...|    59|\n","|negative|I was disgusted b...|    62|\n","|negative|I was shocked bec...|    50|\n","|positive| Highly recommended.|    19|\n","|negative|Waitress was a li...|    38|\n","|negative|This place is not...|    51|\n","|negative|did not like at all.|    20|\n","+--------+--------------------+------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import length\n","\n","# Create a length column to be used as a future feature\n","data_df = df.withColumn('length', length(df['text']))\n","data_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"qnY_XKPyCgwX"},"outputs":[],"source":["# Create all the features to the data set\n","pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n","tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n","stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n","hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n","idf = IDF(inputCol='hash_token', outputCol='idf_token')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G8R5SpHBMe21"},"source":["Note that the StringIndexer encodes a string column to a column of table indexes.\n","\n","We're working with positive and negative game reviews, which will be converted to 0 and 1. This will form our labels, which we'll delve into in the ML unit. The label is what we’re trying to predict: will the review’s given text let us know if it was positive or negative?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"1rrZTxhgGMmi"},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.linalg import Vector\n","\n","# Create feature vectors\n","clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oDizUMkgNBMO"},"source":["We’ll create a feature vector containing the output from the IDFModel (the last stage in the pipeline) and the length. This will combine all the raw features to train the ML model that we’ll be using. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eqj0Ho1oGubx"},"outputs":[],"source":["# Create and run a data processing Pipeline\n","from pyspark.ml import Pipeline\n","\n","data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7_YS9SaTOF-o"},"source":["Import the pipeline from pyspark.ml, and then store a list of the stages created earlier. It’s important to list the stages in the order they need to be executed becausethe output from one stage will then be passed off to another stage."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"S3WP4m7FMggR"},"outputs":[],"source":["# Fit and transform the pipeline\n","cleaner = data_prep_pipeline.fit(data_df)\n","cleaned = cleaner.transform(data_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"colab_type":"code","executionInfo":{"elapsed":1018,"status":"ok","timestamp":1588302923107,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"},"user_tz":420},"id":"VWk_AFCdHFyp","outputId":"f62c3376-6b22-4ade-da84-a66469a66558"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+\n","|label|            features|\n","+-----+--------------------+\n","|  0.0|(262145,[33933,69...|\n","|  1.0|(262145,[15889,13...|\n","|  1.0|(262145,[25570,63...|\n","|  0.0|(262145,[6286,272...|\n","|  0.0|(262145,[6979,255...|\n","|  1.0|(262145,[24417,24...|\n","|  1.0|(262145,[12084,48...|\n","|  1.0|(262145,[3645,963...|\n","|  0.0|(262145,[53777,10...|\n","|  0.0|(262145,[138356,2...|\n","|  0.0|(262145,[24113,25...|\n","|  1.0|(262145,[68867,13...|\n","|  1.0|(262145,[24417,36...|\n","|  0.0|(262145,[18098,24...|\n","|  1.0|(262145,[24417,25...|\n","|  1.0|(262145,[24417,25...|\n","|  0.0|(262145,[31704,21...|\n","|  1.0|(262145,[25570,27...|\n","|  1.0|(262145,[12329,15...|\n","|  1.0|(262145,[8287,139...|\n","+-----+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Show label and resulting features\n","cleaned.select(['label', 'features']).show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vDkiWenQQdnL"},"source":["**Training data** is the data that will be passed to our NLP model that will train our model to predict results. The testing data is used to test our predictions. We can do this with the randomSplit method, which takes in a list of the percent of data we want split into each group. Standard conventions use 70% with training and 30% with testing."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ber33vTmO0EC"},"outputs":[],"source":["# Break data down into a training set and a testing set\n","training, testing = cleaned.randomSplit([0.7, 0.3], 21)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XDsMm9BRQ5BZ"},"source":["The array supplied to randomSplit is the percentage of the data that will be broken into training and testing respectively. So 70% to training and 30% to testing. The second number supplied is called a seed. The seed assures that this random split will also be the same, this is good for when we want to make sure we all have similar results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"f8P9bhD8QVwA"},"outputs":[],"source":["from pyspark.ml.classification import NaiveBayes\n","\n","# Create a Naive Bayes model and fit training data\n","nb = NaiveBayes()\n","predictor = nb.fit(training)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GT_nVrbIRKaQ"},"source":["Import ML model \"NaiveBayes\". **Naive Bayes** is a group of classifier algorithms based on Bayes’ theorem. Bayes theorem provides a way to determine the probability of an event based on new conditions or information that might be related to the event."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"colab_type":"code","executionInfo":{"elapsed":5181,"status":"ok","timestamp":1588303680330,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"},"user_tz":420},"id":"FMLA_nnAQg5p","outputId":"28e5a5a5-c27c-4554-8073-64faf1a7a91c"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n","+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","|negative| \"As for the \"\"mains|    19|  1.0|[\"as, for, the, \"...|      [\"as, \"\"mains]|(262144,[16332,10...|(262144,[16332,10...|(262145,[16332,10...|[-235.05580770267...|[0.03900923601832...|       1.0|\n","|negative|\"I don't know wha...|    85|  1.0|[\"i, don't, know,...|[\"i, know, big, d...|(262144,[8478,158...|(262144,[8478,158...|(262145,[8478,158...|[-876.28450835078...|[5.82709985215757...|       1.0|\n","|negative|\"like the other r...|    82|  1.0|[\"like, the, othe...|[\"like, reviewer,...|(262144,[22808,61...|(262144,[22808,61...|(262145,[22808,61...|[-930.20054206924...|[5.67229347354298...|       1.0|\n","|negative| \"not even a \"\"hello|    19|  1.0|[\"not, even, a, \"...|[\"not, even, \"\"he...|(262144,[174966,2...|(262144,[174966,2...|(262145,[174966,2...|[-259.46346332024...|[0.19845430741939...|       1.0|\n","|negative|              #NAME?|     6|  1.0|            [#name?]|            [#name?]|(262144,[75443],[...|(262144,[75443],[...|(262145,[75443,26...|[-70.880216880965...|[0.93675076661110...|       0.0|\n","+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","only showing top 5 rows\n","\n"]}],"source":["# Transform the model with the testing data\n","test_results = predictor.transform(testing)\n","test_results.show(5)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xO1c5v1hR4Ii"},"source":["This prediction column will indicate with a 1.0 if the model thinks this review is negative and 0.0 if it thinks it’s positive."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":6653,"status":"ok","timestamp":1588303867249,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"},"user_tz":420},"id":"ro3OhDeNROqe","outputId":"d8fc4ce9-050f-4eb1-f970-c68420bf8913"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuray of model at predicting reviews was: 0.718984\n"]}],"source":["# Use the Class Evaluator for a cleaner description\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","acc_eval = MulticlassClassificationEvaluator()\n","acc = acc_eval.evaluate(test_results)\n","print(\"Accuray of model at predicting reviews was: %f\" % acc)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aWU2R7cSSefV"},"source":["**MulticlassClassificationEvaluator** displays how accurate our model is in determining if a review will be positive or negative based solely on the text within a review."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WRDxjn7Ioqwu"},"source":["total number of correct predictions for X\n","/\n","total number of predictions made"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"K855clfxSZLu"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN0Pnf5mfgWlry5XZLtyPUg","name":"Yelp_NLP.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
